{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice.\n",
        "\n",
        "Answer: Multithreading: When to Use It\n",
        "Multithreading is ideal when your program performs tasks that are I/O-bound or tasks that need to be shared between threads.\n",
        "\n",
        "I/O-bound tasks:\n",
        "\n",
        "When your program spends most of its time waiting for external resources, such as network responses, file I/O, or database queries, multithreading can be highly effective. This is because while one thread is waiting for I/O operations to complete, other threads can continue executing.\n",
        "\n",
        "Example: Downloading multiple files concurrently from the internet, reading from disk, or waiting for user input.\n",
        "\n",
        "\n",
        "Shared Memory:\n",
        "\n",
        "In multithreading, all threads share the same memory space. This can be an advantage when multiple threads need to access shared resources or data structures, such as buffers, lists, or caches, because they can directly access and modify these shared objects.\n",
        "\n",
        "Example: A web server where multiple threads handle different HTTP requests but work with the same pool of database connections or shared cache.\n",
        "\n",
        "\n",
        "Lightweight Tasks:\n",
        "\n",
        "Threads are lighter in terms of system overhead compared to processes. If your tasks are small and require frequent context switching or are not computationally heavy, multithreading is a better choice.\n",
        "\n",
        "Example: Implementing a GUI application where multiple threads handle different UI events or background tasks without consuming significant CPU resources.\n",
        "\n",
        "\n",
        "Low Context-Switching Overhead:\n",
        "\n",
        "When the overhead of switching between threads is lower than the cost of creating new processes, multithreading is generally more efficient.\n",
        "\n",
        "Example: Simulating a system where tasks are interdependent, like running a simulation where multiple components (each represented by a thread) need to frequently communicate.\n",
        "\n",
        "\n",
        "Thread Synchronization Needs:\n",
        "\n",
        "If the tasks need to be synchronized or coordinated within a shared context (e.g., using mutexes, semaphores, or barriers), multithreading is a natural choice.\n",
        "\n",
        "Example: Threaded computation where one thread produces data and others consume it (e.g., producer-consumer problem).\n",
        "\n",
        "Multiprocessing: When to Use It\n",
        "Multiprocessing is preferable when the tasks are CPU-bound or when you need to avoid the Global Interpreter Lock (GIL) in Python, among other scenarios where processes are more isolated and independent.\n",
        "\n",
        "CPU-bound tasks:\n",
        "\n",
        "Multiprocessing is better suited for tasks that require a lot of CPU power, where tasks perform heavy computation (like number-crunching or image processing). Python’s Global Interpreter Lock (GIL) can hinder multithreading when it comes to CPU-bound tasks, as only one thread can execute Python bytecode at a time. Multiprocessing bypasses this by running separate processes, each with its own Python interpreter and memory space.\n",
        "\n",
        "Example: Image processing, machine learning training, numerical simulations, or data analysis with large datasets.\n",
        "Process Isolation:\n",
        "\n",
        "Processes are independent and do not share memory space, making them more isolated from one another. This can be advantageous if the tasks you are running need to be isolated (e.g., preventing one task from affecting the memory of another). Each process runs in its own memory space, so there is less risk of memory corruption.\n",
        "\n",
        "Example: Running separate instances of a web scraper for different websites, where you want complete isolation between each scraper’s state.\n",
        "Avoiding GIL in Python:\n",
        "\n",
        "In Python, the GIL prevents more than one thread from executing Python bytecode at once. For CPU-bound tasks, this can be a bottleneck. With multiprocessing, each process runs in its own memory space and has its own interpreter, thus bypassing the GIL limitations.\n",
        "Example: Using Python for data processing with libraries like multiprocessing or concurrent.futures to take full advantage of multiple CPU cores.\n",
        "\n",
        "Heavy Computational Tasks:\n",
        "\n",
        "When each task can run independently and requires a significant amount of computation, multiprocessing can speed things up by using multiple CPUs or cores.\n",
        "\n",
        "Example: Parallelizing a large matrix multiplication or solving large-scale optimization problems.\n",
        "Fault Isolation:\n",
        "\n",
        "Since processes are independent, a crash or failure in one process will not affect the others. This is useful when tasks are prone to failure and you need fault tolerance.\n",
        "Example: Running several independent tasks that could each fail (e.g., data scraping, batch jobs) without affecting the main program.\n"
      ],
      "metadata": {
        "id": "7pgo_9lv8mL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Describe what a process pool is and how it helps in managing multiple processes efficiently.**\n",
        "\n",
        "Answer:A process pool is a collection of pre-created worker processes that are used to perform tasks in parallel, managing the execution of multiple tasks concurrently without the overhead of repeatedly creating and destroying processes. The process pool pattern is particularly useful for efficiently handling large numbers of parallel tasks, especially in environments that require distributed computation, such as data processing or computationally intensive workloads.\n",
        "\n",
        "The process pool pattern is common in programming frameworks like Python's multiprocessing module, which provides the Pool class to manage a pool of worker processes.\n",
        "\n",
        "**Key Features of a Process Pool**\n",
        "\n",
        "Pre-creation of Processes:\n",
        "\n",
        "A pool maintains a set of worker processes that are created when the pool is initialized. These processes are idle but ready to perform tasks when needed, rather than having to create new processes each time a task is assigned.\n",
        "\n",
        "Task Distribution:\n",
        "\n",
        "Once a task is submitted to the pool, the pool assigns it to an available worker process. If no process is available, the task is queued until a worker process becomes free. This helps in managing the number of concurrent processes without overwhelming the system.\n",
        "\n",
        "Efficient Management:\n",
        "\n",
        "The pool ensures that there is a fixed number of worker processes running at any time, which helps prevent the overhead of constantly spawning and terminating processes. It also ensures that the system doesn’t get overloaded with too many processes running simultaneously.\n",
        "\n",
        "Parallel Execution:\n",
        "\n",
        "The process pool enables parallelism by distributing tasks among multiple processes. Each process in the pool can run independently, utilizing separate CPU cores, and thus improving the overall speed of execution for CPU-bound tasks."
      ],
      "metadata": {
        "id": "KLtT8HCO9MUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Explain what multiprocessing is and why it is used in Python programs**.\n",
        "\n",
        "Answer:\n",
        "1. Bypassing the Global Interpreter Lock (GIL)\n",
        "\n",
        "GIL: Python's Global Interpreter Lock (GIL) is a mutex (mutual exclusion) that protects access to Python objects in a multi-threaded environment, ensuring that only one thread executes Python bytecode at a time. This means that in a multi-threaded Python program, even though there may be multiple threads, only one thread can execute Python code at a time. This is particularly problematic for CPU-bound tasks where you want to fully utilize multiple cores.\n",
        "\n",
        "Multiprocessing bypasses the GIL by creating separate processes, each with its own Python interpreter and memory space. Since processes run independently, they are not subject to the GIL, which allows true parallelism for CPU-bound tasks (i.e., multiple processes can run on different CPU cores simultaneously).\n",
        "\n",
        "Example: If you're doing heavy numerical computation (e.g., matrix multiplication, sorting large datasets), using the multiprocessing module can significantly speed up the execution by distributing the tasks across multiple cores, whereas threads would be limited by the GIL.\n",
        "\n",
        "2. Parallelism for CPU-bound Tasks\n",
        "\n",
        "CPU-bound tasks are operations that are computationally intensive, requiring significant processing power from the CPU. Examples include data crunching, number-crunching algorithms, scientific simulations, image processing, and machine learning model training.\n",
        "\n",
        "Why Multiprocessing is Effective:\n",
        "\n",
        "When you have a CPU-bound task, multiprocessing can distribute the workload across multiple CPU cores or even multiple machines (in distributed computing environments), allowing each process to run independently and compute in parallel. This maximizes the utilization of available cores.\n",
        "For example, if you're running a machine learning training process, you can use multiprocessing to parallelize data loading, preprocessing, or training across multiple processes.\n",
        "Example: A task like computing the sum of a large array could be divided into smaller chunks, with each chunk processed by a separate process. Once each process finishes, the results can be combined to produce the final sum.\n",
        "\n",
        "3. Isolated Processes\n",
        "\n",
        "One of the key characteristics of multiprocessing is that each process has its own memory space, which provides isolation between tasks. This can be an advantage in scenarios where you need fault tolerance or where different tasks must run independently without sharing resources or data.\n",
        "\n",
        "Example: If you're running multiple independent web scrapers in parallel, you can isolate each scraper in its own process, avoiding issues where one scraper could affect the state or data of another.\n",
        "\n",
        "Benefits of Process Isolation:\n",
        "\n",
        "If a process crashes, it doesn’t affect the other processes.\n",
        "Since memory space is isolated, there’s less chance of race conditions or data corruption compared to threads, where shared memory can introduce complex synchronization issues.\n",
        "\n",
        "4. Improved Fault Tolerance\n",
        "\n",
        "Because processes run independently of one another, the failure of one process typically doesn’t affect others. This makes multiprocessing more fault-tolerant compared to multithreading, where a bug or crash in one thread could potentially bring down the entire program.\n",
        "\n",
        "Example: If you’re running a large batch processing system and one process encounters an error, you can simply restart or handle that specific process, while the other processes continue working without interruption.\n",
        "\n",
        "5. Concurrency for I/O-bound Tasks\n",
        "\n",
        "While multithreading is typically more suited for I/O-bound tasks (tasks that spend a lot of time waiting for external resources like files, network, or databases), multiprocessing can still be useful for I/O-bound tasks in Python when you want to distribute work across multiple CPU cores or run many independent tasks concurrently (e.g., launching multiple network requests or database queries in parallel).\n",
        "\n",
        "Example: When crawling or scraping data from multiple websites, you can use multiprocessing to spawn multiple processes, each responsible for fetching data from a different site, speeding up the overall process.\n",
        "\n",
        "6. Resource Management\n",
        "\n",
        "Multiprocessing allows for better resource management, especially when dealing with large tasks or datasets. You can manage the number of processes running at once and prevent the system from becoming overwhelmed by controlling the size of the process pool.\n",
        "\n",
        "Example: Using a process pool, you can define the number of concurrent processes that should be running, ensuring that system resources like CPU and memory are utilized efficiently and without overwhelming the system.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O6Nvc9nb_kqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "# Function to compute square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Create a pool of 4 worker processes\n",
        "with Pool(4) as pool:\n",
        "    # Map the square function to a list of numbers\n",
        "    result = pool.map(square, [1, 2, 3, 4, 5, 6, 7, 8])\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9azhTRaAOYJ",
        "outputId": "d57bead1-ce84-4970-a3a2-ea86e11f7c76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25, 36, 49, 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock.\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "1O-lXuXVAQCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Lock object to prevent race conditions\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        with lock:  # Ensure that only one thread can add at a time\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added {i} to the list\")\n",
        "        time.sleep(0.1)  # Simulate some work\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for _ in range(10):\n",
        "        time.sleep(0.2)  # Simulate waiting for numbers to be added\n",
        "        with lock:  # Ensure that only one thread can remove at a time\n",
        "            if shared_list:\n",
        "                removed = shared_list.pop(0)\n",
        "                print(f\"Removed {removed} from the list\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove\")\n",
        "\n",
        "# Create two threads: one for adding and one for removing\n",
        "thread_add = threading.Thread(target=add_numbers)\n",
        "thread_remove = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start both threads\n",
        "thread_add.start()\n",
        "thread_remove.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "thread_add.join()\n",
        "thread_remove.join()\n",
        "\n",
        "print(\"Final shared list:\", shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPr7q4BiAciq",
        "outputId": "0300356e-9b81-4d64-9491-5a24587d963d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 to the list\n",
            "Added 1 to the list\n",
            "Added 2 to the list\n",
            "Removed 0 from the list\n",
            "Added 3 to the list\n",
            "Added 4 to the list\n",
            "Removed 1 from the list\n",
            "Added 5 to the list\n",
            "Added 6 to the list\n",
            "Removed 2 from the list\n",
            "Added 7 to the list\n",
            "Added 8 to the list\n",
            "Removed 3 from the list\n",
            "Added 9 to the list\n",
            "Removed 4 from the list\n",
            "Removed 5 from the list\n",
            "Removed 6 from the list\n",
            "Removed 7 from the list\n",
            "Removed 8 from the list\n",
            "Removed 9 from the list\n",
            "Final shared list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes.\n",
        "\n",
        "Answer:\n",
        "\n",
        "1. **Sharing Data Between Threads (Multithreading**)\n",
        "\n",
        "Python provides several tools and techniques to share data safely between threads. Since threads share the same memory space, data synchronization is required to ensure consistency.\n",
        "\n",
        "a. **Threading Locks (threading.Lock**)\n",
        "\n",
        "A lock is a simple synchronization primitive that prevents more than one thread from accessing a shared resource at the same time. The threading.Lock object can be acquired and released to manage access to critical sections of the code.\n",
        "Usage: You wrap the code that accesses shared data with a with lock or manually acquire and release the lock."
      ],
      "metadata": {
        "id": "GS8hRkefAfMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "shared_data = []\n",
        "\n",
        "# Lock to synchronize access\n",
        "lock = threading.Lock()\n",
        "\n",
        "def add_data():\n",
        "    with lock:  # Ensure exclusive access\n",
        "        shared_data.append(\"data\")\n",
        "\n",
        "def remove_data():\n",
        "    with lock:\n",
        "        if shared_data:\n",
        "            shared_data.pop()\n"
      ],
      "metadata": {
        "id": "99l7419oFPF6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. threading.Semaphore**\n",
        "\n",
        "A semaphore is similar to a lock but can be initialized with a value greater than 1, allowing a fixed number of threads to access a shared resource concurrently. This can be useful when you have a bounded resource that can support a fixed number of threads accessing it simultaneously."
      ],
      "metadata": {
        "id": "W4kD1OiJFSHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "# Semaphore with a limit of 2 threads\n",
        "semaphore = threading.Semaphore(2)\n",
        "\n",
        "def access_shared_resource():\n",
        "    with semaphore:\n",
        "        # Critical section where shared resource is accessed\n",
        "        print(\"Thread accessing the resource\")\n"
      ],
      "metadata": {
        "id": "aGmXR8ONFWBv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.** Sharing Data Between Processes (Multiprocessing)**\n",
        "\n",
        "In contrast to threads, processes in Python do not share the same memory space, which makes inter-process communication (IPC) more complex. Python provides several tools for safely sharing data between processes.\n",
        "\n",
        "**a. multiprocessing.Queue**\n",
        "\n",
        "A Queue is a process-safe, FIFO data structure that allows processes to exchange data. It is commonly used for sending and receiving data between processes."
      ],
      "metadata": {
        "id": "4k0tXWUEFYEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def producer(q):\n",
        "    q.put(\"data\")\n",
        "\n",
        "def consumer(q):\n",
        "    item = q.get()\n",
        "    print(f\"Consumed: {item}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    q = multiprocessing.Queue()\n",
        "    p1 = multiprocessing.Process(target=producer, args=(q,))\n",
        "    p2 = multiprocessing.Process(target=consumer, args=(q,))\n",
        "\n",
        "    p1.start()\n",
        "    p2.start()\n",
        "\n",
        "    p1.join()\n",
        "    p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW5vR0u9Ff-3",
        "outputId": "139b22a2-7bbf-4297-e537-5156c27f1acf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consumed: data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. **multiprocessing.Pipe**\n",
        "\n",
        "A Pipe is a two-way communication channel between processes. A pipe has two ends: one for sending data and one for receiving data. It can be used when two processes need to communicate directly."
      ],
      "metadata": {
        "id": "iZ88LRjjFjzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def producer(pipe):\n",
        "    pipe.send(\"data\")\n",
        "\n",
        "def consumer(pipe):\n",
        "    data = pipe.recv()\n",
        "    print(f\"Consumed: {data}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parent_conn, child_conn = multiprocessing.Pipe()\n",
        "\n",
        "    p1 = multiprocessing.Process(target=producer, args=(child_conn,))\n",
        "    p2 = multiprocessing.Process(target=consumer, args=(parent_conn,))\n",
        "\n",
        "    p1.start()\n",
        "    p2.start()\n",
        "\n",
        "    p1.join()\n",
        "    p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d19WtuVhFmD4",
        "outputId": "6c5a1768-9610-49fa-b7f7-2d2ea5e13106"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consumed: data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
        "doing so**\n",
        "\n",
        "Answer: **Why Exception Handling is Crucial in Concurrent Program**\n",
        "\n",
        "Multiple Execution Threads or Processes:\n",
        "\n",
        "In concurrent programs, multiple threads or processes run independently. If one of them encounters an exception, it can cause unintended consequences. For example, if one thread crashes, it might leave shared data in an inconsistent state, affecting other threads that depend on that data.\n",
        "\n",
        "Unpredictability of Execution Flow:\n",
        "\n",
        "In a multithreaded or multiprocessing environment, the order of execution is not guaranteed. This means that exceptions might not occur where you'd expect them, making it more difficult to detect and handle errors immediately. A thread or process could throw an exception at an unpredictable point, and without proper handling, this can lead to difficult-to-reproduce bugs.\n",
        "\n",
        "Resource Leaks and Deadlocks:\n",
        "\n",
        "If an exception occurs during critical operations (e.g., file handling, network communication), failing to handle it can lead to resource leaks (like unclosed files or database connections) or deadlocks. If a thread holds a lock and crashes, other threads might be blocked, resulting in a deadlock.\n",
        "\n",
        "Safety and Clean Shutdown:\n",
        "\n",
        "Proper exception handling is necessary for ensuring that when something goes wrong, the program can gracefully shut down, releasing resources properly, and avoiding leaving shared data in an inconsistent or corrupted state.\n",
        "\n",
        "Error Propagation:\n",
        "\n",
        "In concurrent programs, one thread or process may depend on another. If one thread raises an exception, it may affect other threads that depend on its output. Exception handling must ensure that exceptions can be communicated and handled correctly across multiple threads or processes.\n",
        "\n",
        "**Techniques for Handling Exceptions in Concurrent Programs**\n",
        "\n",
        "1. Handling Exceptions in Threads\n",
        "\n",
        "a. Using try-except Blocks Inside Threads"
      ],
      "metadata": {
        "id": "Jaw8vi4SFzHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def thread_function():\n",
        "    try:\n",
        "        # Simulate some work that might raise an exception\n",
        "        print(\"Thread starting.\")\n",
        "        raise ValueError(\"An error occurred in the thread.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in thread: {e}\")\n",
        "\n",
        "# Create a thread\n",
        "thread = threading.Thread(target=thread_function)\n",
        "thread.start()\n",
        "thread.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxKBBJacGlhw",
        "outputId": "2caba4ab-beea-46e0-99e4-303ba6bbb6e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread starting.\n",
            "Exception in thread: An error occurred in the thread.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Using a ThreadPoolExecutor with concurrent.futures"
      ],
      "metadata": {
        "id": "5DJSpq56GoQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def thread_function(x):\n",
        "    if x == 3:\n",
        "        raise ValueError(\"An error occurred.\")\n",
        "    return x * 2\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
        "    futures = [executor.submit(thread_function, i) for i in range(5)]\n",
        "\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        try:\n",
        "            result = future.result()  # This will raise the exception if occurred\n",
        "            print(f\"Result: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Exception captured: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmzrI89MGqOy",
        "outputId": "1fec5ba5-9c46-4d79-9cf0-22f6fa670bcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: 0\n",
            "Result: 2\n",
            "Result: 4\n",
            "Exception captured: An error occurred.\n",
            "Result: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Handling Exceptions in Processes**\n",
        "\n",
        "a. Using try-except Blocks in Processes"
      ],
      "metadata": {
        "id": "qxJW6FbeGtiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def process_function():\n",
        "    try:\n",
        "        # Simulate work that may raise an exception\n",
        "        print(\"Process starting.\")\n",
        "        raise ValueError(\"An error occurred in the process.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in process: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process = multiprocessing.Process(target=process_function)\n",
        "    process.start()\n",
        "    process.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yo5YJjIGxVg",
        "outputId": "62cf812a-cc67-47d6-e37d-4da09fa8a7a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process starting.\n",
            "Exception in process: An error occurred in the process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Using multiprocessing.Pool with Exception Handling"
      ],
      "metadata": {
        "id": "-jFoMrC3GzS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def process_function(x):\n",
        "    if x == 3:\n",
        "        raise ValueError(\"An error occurred.\")\n",
        "    return x * 2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with multiprocessing.Pool(4) as pool:\n",
        "        results = []\n",
        "        for i in range(5):\n",
        "            results.append(pool.apply_async(process_function, (i,)))\n",
        "\n",
        "        for result in results:\n",
        "            try:\n",
        "                print(result.get())  # Will raise exception if occurred\n",
        "            except Exception as e:\n",
        "                print(f\"Exception captured: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNYdh2z4G2N3",
        "outputId": "e6da26f8-20ef-4f7f-9bdd-9c0bf55c6a8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "2\n",
            "4\n",
            "Exception captured: An error occurred.\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Handling Exceptions Across Threads/Processes Using Callbacks**\n",
        "\n",
        "a. Using a Queue to Communicate Exceptions"
      ],
      "metadata": {
        "id": "5Qq0cybKG8nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import queue\n",
        "\n",
        "def worker(q):\n",
        "    try:\n",
        "        # Simulate work that might fail\n",
        "        raise ValueError(\"Error in worker thread\")\n",
        "    except Exception as e:\n",
        "        q.put(e)  # Put exception in the queue to send back to main thread\n",
        "\n",
        "q = queue.Queue()\n",
        "t = threading.Thread(target=worker, args=(q,))\n",
        "t.start()\n",
        "t.join()\n",
        "\n",
        "# Retrieve exception from the queue and handle it\n",
        "while not q.empty():\n",
        "    exception = q.get()\n",
        "    print(f\"Handled exception: {exception}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1KE0v4bHA1o",
        "outputId": "8edece7b-0a26-4ba7-f321-4b24157320c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handled exception: Error in worker thread\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Using concurrent.futures Exception Handling"
      ],
      "metadata": {
        "id": "hg28GUV-HEfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def worker_function(x):\n",
        "    if x == 5:\n",
        "        raise ValueError(\"Error in worker process\")\n",
        "    return x * 2\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    futures = [executor.submit(worker_function, i) for i in range(10)]\n",
        "\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        try:\n",
        "            print(future.result())  # Will raise exception if it occurred\n",
        "        except Exception as e:\n",
        "            print(f\"Caught exception: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qFqWYbFHFHo",
        "outputId": "296338ae-c30e-401d-afdf-22844a3bd4e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "16\n",
            "4\n",
            "Caught exception: Error in worker process\n",
            "14\n",
            "18\n",
            "0\n",
            "8\n",
            "12\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the thread**\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "sNCI9zudHIpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Create a ThreadPoolExecutor with a pool of 5 threads\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        # Submit tasks to the thread pool for factorial calculation of numbers 1 to 10\n",
        "        numbers = range(1, 11)\n",
        "        futures = {executor.submit(calculate_factorial, num): num for num in numbers}\n",
        "\n",
        "        # Process results as they become available\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            num = futures[future]\n",
        "            try:\n",
        "                result = future.result()  # This will raise any exception that occurred in the thread\n",
        "                print(f\"Factorial of {num} is {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating factorial for {num}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35I1lpR5HXGh",
        "outputId": "7eea427b-d842-4de6-9b17-4db348d2024d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 8 is 40320\n",
            "Factorial of 6 is 720\n",
            "Factorial of 1 is 1\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 3 is 6\n",
            "Factorial of 5 is 120\n",
            "Factorial of 2 is 2\n",
            "Factorial of 10 is 3628800\n",
            "Factorial of 4 is 24\n",
            "Factorial of 7 is 5040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes)**\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "9INEAYibHda5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# Main function to use Pool for parallel computation and measure time\n",
        "def main(pool_size):\n",
        "    numbers = list(range(1, 11))  # List of numbers from 1 to 10\n",
        "\n",
        "    # Create a Pool of processes\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        start_time = time.time()  # Record start time\n",
        "\n",
        "        # Compute squares in parallel using map\n",
        "        squares = pool.map(compute_square, numbers)\n",
        "\n",
        "        end_time = time.time()  # Record end time\n",
        "\n",
        "        # Print the results\n",
        "        print(f\"Squares with {pool_size} processes: {squares}\")\n",
        "        print(f\"Time taken with {pool_size} processes: {end_time - start_time:.4f} seconds\\n\")\n",
        "\n",
        "# Run the program for different pool sizes\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [2, 4, 8]  # Different pool sizes to test\n",
        "\n",
        "    for size in pool_sizes:\n",
        "        main(size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSsW27yzHpFA",
        "outputId": "f178ad13-6282-44ed-faf0-4e7a32e583dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squares with 2 processes: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with 2 processes: 0.0020 seconds\n",
            "\n",
            "Squares with 4 processes: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with 4 processes: 0.0041 seconds\n",
            "\n",
            "Squares with 8 processes: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with 8 processes: 0.0042 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}